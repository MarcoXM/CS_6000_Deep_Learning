{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# Helper function!\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) /np.sum(np.exp(z),axis = 1).reshape(-1,1)\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return z*(1-z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network(object):\n",
    "    def __init__(self,size): # (784 , 256, 10) 说是三层layer 其实就两个\n",
    "        ## size should be a list of int or tuple of int!\n",
    "        \n",
    "        self.num_mt = len(size) - 1 # 2 这里我们要取2 就是我们有两个矩阵\n",
    "        self.size = size  #无聊存一下 \n",
    "        self.output = [0] * len(size) # output 也是每次的input 一共三个\n",
    "        self.errorterm = [0] * (len(size)-1)  # 这就是就误差 乘以sigmoid 导数\n",
    "        self.delta = []\n",
    "        self.error = None # 就是最后的误差\n",
    "\n",
    "        self.bias_dict = {'bias_{}'.format(k): self._init_b(size[k-1],size[k]) for k in range(1,len(size))}  \n",
    "        # One is 256 and two has 10 bias.\n",
    "        \n",
    "        self.weights_dict = {'weights_{}'.format(k): self._init_W(size[k-1],size[k]) for k in range(1,len(size))}\n",
    "\n",
    "    def _init_W(self, n_in, n_out):\n",
    "        bound = 2.0 / (n_in + n_out)\n",
    "        W = np.random.uniform(-bound, bound, (n_in, n_out))\n",
    "        return W\n",
    "    \n",
    "    def _init_b(self,n_in,n_out):\n",
    "        bound = 2.0 / (n_in + n_out)\n",
    "        b = np.random.uniform(-bound, bound, (1, n_out))\n",
    "        return b\n",
    "        \n",
    "    \n",
    "    def forward(self,input_): # update output in each layers\n",
    "        self.output[0] = input_\n",
    "        for n,(w,b) in enumerate(zip(self.weights_dict.values(),self.bias_dict.values())): # 0,1\n",
    "            n += 1\n",
    "            if n == self.num_mt: #last layer ! is 2 就是说到了最后一层就softmax\n",
    "                input_ = softmax(np.dot(input_,w) + b) # when it comes to the last layers\n",
    "                \n",
    "            else:\n",
    "                input_ = sigmoid(np.dot(input_,w) + b)\n",
    "            self.output[n] = input_\n",
    "        return input_\n",
    "\n",
    "    def loss(self,output,target):\n",
    "        loss = 0.0\n",
    "        # target is a array , and output is a matrix.\n",
    "        self.bs = output.shape[0]\n",
    "        log_likelihood = -np.log(output[range(self.bs),target])\n",
    "        loss = np.sum(log_likelihood) / self.bs\n",
    "        return loss\n",
    "    \n",
    "    def backpro(self,target,learnrate = 0.001): # devivertive of softmax is looks like sigmoid !\n",
    "\n",
    "        self.lr = learnrate\n",
    "        deltaw = [np.zeros(w.shape) for w in self.weights_dict.values()] # 变化量矩阵 有两个！\n",
    "        deltab = [np.zeros(b.shape) for b in self.bias_dict.values()]\n",
    "        y_idx = np.argmax(softmax(self.output[-1]),axis =1)\n",
    "        y_matrix = np.eye(self.size[-1])[target]\n",
    "        \n",
    "        #print(y_idx)\n",
    "        for i in range(self.num_mt)[::-1]: # we have 2 matrix here 1,0\n",
    "            #print(self.error)\n",
    "            self.errorterm[i] = (self.output[-1] - y_matrix)  #errer term softmax and loss dev\n",
    "\n",
    "            if i == self.num_mt -1 : #== 1\n",
    "                hidden_error = np.dot(self.weights_dict['weights_{}'.format(i+1)], self.errorterm[i].sum(axis=0))\n",
    "                #print(hidden_error.shape)\n",
    "            \n",
    "            elif i != self.num_mt -1 : # 0\n",
    "                self.errorterm[i] = hidden_error * sigmoid_prime(self.output[i+1])\n",
    "                #print(hidden_error.shape)\n",
    "          \n",
    "        \n",
    "        for j in range(self.num_mt): # get delta ~ 0,\n",
    "            #print(deltaw[j].shape)\n",
    "            deltaw[j] += np.dot(self.output[j].T,self.errorterm[j])\n",
    "            deltab[j] += np.sum(self.errorterm[j],axis=0)\n",
    "            \n",
    "\n",
    "        \n",
    "        for k in range(self.num_mt):\n",
    "            #print(deltab[k].shape)\n",
    "            self.weights_dict['weights_{}'.format(k+1)] -= self.lr * deltaw[k]/self.bs # update hidden-to-output weights with gradient descent step\n",
    "            self.bias_dict['bias_{}'.format(k+1)] -= self.lr * deltab[k]/self.bs\n",
    "    \n",
    "        return self.weights_dict,self.bias_dict\n",
    "  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "nn = Network([784,256,10])\n",
    "x_train = np.load('mnist.train.npy')\n",
    "y_train = np.load('mnist.trainlabel.npy')\n",
    "x_test = np.load('mnist.test.npy')\n",
    "x,xt,y,yt = train_test_split(x_train,y_train,test_size = 0.2,random_state = 224)\n",
    "for e in range(10):\n",
    "    for i in range(0,x.shape[0],32):\n",
    "        data,target = x[i:i+32],y[i:i+32]\n",
    "        data = data.reshape(-1,784)\n",
    "        output = nn.forward(data)\n",
    "        loss = nn.loss(output,target)\n",
    "        if (i+1)%50 == 0:\n",
    "            print(loss)\n",
    "        nn.backpro(target,learnrate=0.01)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nn.output[-1] - np.eye(nn.size[-1])[[2,5]]).sum(axis=0).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x[0:0+100].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8682142857142857"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = nn.forward(xt.reshape(-1,784))\n",
    "sum(np.argmax(softmax(output),axis=1)==yt)/len(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.25569395e-01, 4.56553399e-07, 8.36464449e-04, ...,\n",
       "        1.90678206e-05, 5.50787785e-03, 1.67895064e-04],\n",
       "       [1.18179855e-01, 5.81255813e-06, 5.32236834e-02, ...,\n",
       "        1.58255263e-03, 2.62219985e-03, 2.55653119e-02],\n",
       "       [7.59665884e-02, 1.62972683e-05, 5.53559847e-04, ...,\n",
       "        4.39139010e-03, 1.31456531e-02, 1.01101204e-02],\n",
       "       ...,\n",
       "       [2.72618597e-05, 6.34925199e-07, 9.70451935e-06, ...,\n",
       "        4.56800824e-04, 4.07842238e-04, 6.04758843e-02],\n",
       "       [1.95580593e-04, 9.27223883e-06, 1.56488068e-02, ...,\n",
       "        4.40424476e-05, 2.82022074e-04, 2.59933588e-03],\n",
       "       [9.94219941e-05, 1.36568025e-04, 2.51112163e-04, ...,\n",
       "        1.50123572e-01, 2.22722852e-02, 7.71600609e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
