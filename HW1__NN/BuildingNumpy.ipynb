{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# Helper function!\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) /np.sum(np.exp(z),axis = 1).reshape(-1,1)\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return z*(1-z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network(object):\n",
    "    def __init__(self,size): # (784 , 256, 10) 说是三层layer 其实就两个\n",
    "        ## size should be a list of int or tuple of int!\n",
    "        \n",
    "        self.num_mt = len(size) - 1 # 2 这里我们要取2 就是我们有两个矩阵\n",
    "        self.size = size  #无聊存一下 \n",
    "        self.output = [0] * len(size) # output 也是每次的input 一共三个\n",
    "        self.errorterm = [0] * (len(size)-1)  # 这就是就误差 乘以sigmoid 导数\n",
    "        self.delta = []\n",
    "        self.error = None # 就是最后的误差\n",
    "\n",
    "        self.bias_dict = {'bias_{}'.format(k): self._init_b(size[k-1],size[k]) for k in range(1,len(size))}  \n",
    "        # One is 256 and two has 10 bias.\n",
    "        \n",
    "        self.weights_dict = {'weights_{}'.format(k): self._init_W(size[k-1],size[k]) for k in range(1,len(size))}\n",
    "\n",
    "    def _init_W(self, n_in, n_out):\n",
    "        bound = 2.0 / (n_in + n_out)\n",
    "        W = np.random.uniform(-bound, bound, (n_in, n_out))\n",
    "        return W\n",
    "    \n",
    "    def _init_b(self,n_in,n_out):\n",
    "        bound = 2.0 / (n_in + n_out)\n",
    "        b = np.random.uniform(-bound, bound, (1, n_out))\n",
    "        return b\n",
    "        \n",
    "    \n",
    "    def forward(self,input_): # update output in each layers\n",
    "        self.output[0] = input_\n",
    "        for n,(w,b) in enumerate(zip(self.weights_dict.values(),self.bias_dict.values())): # 0,1\n",
    "            n += 1\n",
    "            if n == self.num_mt: #last layer ! is 2 就是说到了最后一层就softmax\n",
    "                input_ = softmax(np.dot(input_,w) + b) # when it comes to the last layers\n",
    "                \n",
    "            else:\n",
    "                input_ = sigmoid(np.dot(input_,w) + b)\n",
    "            self.output[n] = input_\n",
    "        return input_\n",
    "\n",
    "    def loss(self,output,target):\n",
    "        loss = 0.0\n",
    "        # target is a array , and output is a matrix.\n",
    "        self.bs = output.shape[0]\n",
    "        log_likelihood = -np.log(output[range(self.bs),target])\n",
    "        loss = np.sum(log_likelihood) / self.bs\n",
    "        return loss\n",
    "    \n",
    "    def backpro(self,target,learnrate = 0.001): # devivertive of softmax is looks like sigmoid !\n",
    "\n",
    "        self.lr = learnrate\n",
    "        deltaw = [np.zeros(w.shape) for w in self.weights_dict.values()] # 变化量矩阵 有两个！\n",
    "        deltab = [np.zeros(b.shape) for b in self.bias_dict.values()]\n",
    "        y_idx = np.argmax(softmax(self.output[-1]),axis =1)\n",
    "        y_matrix = np.eye(self.size[-1])[target]\n",
    "        \n",
    "        #print(y_idx)\n",
    "        for i in range(self.num_mt)[::-1]: # we have 2 matrix here 1,0\n",
    "            #print(self.error)\n",
    "            self.errorterm[i] = (self.output[-1] - y_matrix)  #errer term softmax and loss dev\n",
    "\n",
    "            if i == self.num_mt -1 : #== 1\n",
    "                hidden_error = np.dot(self.weights_dict['weights_{}'.format(i+1)], self.errorterm[i].sum(axis=0))\n",
    "                #print(hidden_error.shape)\n",
    "            \n",
    "            elif i != self.num_mt -1 : # 0\n",
    "                self.errorterm[i] = hidden_error * sigmoid_prime(self.output[i+1])\n",
    "                #print(hidden_error.shape)\n",
    "          \n",
    "        \n",
    "        for j in range(self.num_mt): # get delta ~ 0,\n",
    "            #print(deltaw[j].shape)\n",
    "            deltaw[j] += np.dot(self.output[j].T,self.errorterm[j])\n",
    "            deltab[j] += np.sum(self.errorterm[j],axis=0)\n",
    "            \n",
    "\n",
    "        \n",
    "        for k in range(self.num_mt):\n",
    "            #print(deltab[k].shape)\n",
    "            self.weights_dict['weights_{}'.format(k+1)] -= self.lr * deltaw[k]/self.bs # update hidden-to-output weights with gradient descent step\n",
    "            self.bias_dict['bias_{}'.format(k+1)] -= self.lr * deltab[k]/self.bs\n",
    "    \n",
    "        return self.weights_dict,self.bias_dict\n",
    "  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('output_data/mnist.train.npy')\n",
    "y_train = np.load('output_data/mnist.trainlabel.npy') #54000\n",
    "x_test = np.load('output_data/mnist.test.npy') # 15400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab46f1a6f1a48ccbd0ba781d0650d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "nn = Network([784,256,10])\n",
    "x,xt,y,yt = train_test_split(x_train,y_train,test_size = 0.2,random_state = 224)\n",
    "for e in tqdm(range(100)):\n",
    "    for i in range(0,x.shape[0],32):\n",
    "        data,target = x[i:i+32],y[i:i+32]\n",
    "        data = data.reshape(-1,784)\n",
    "        output = nn.forward(data)\n",
    "        loss = nn.loss(output,target)\n",
    "        if (i+1)%50 == 0:\n",
    "            print(loss)\n",
    "        nn.backpro(target,learnrate=0.01)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9291071428571429"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = nn.forward(xt.reshape(-1,784))\n",
    "sum(np.argmax(softmax(output),axis=1)==yt)/len(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.869375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 5, ..., 4, 6, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 5, ..., 4, 6, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(softmax(output),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.test.npy        mnist.trainlabel.npy\r\n",
      "mnist.train.npy       sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  class\n",
       "0   1      7\n",
       "1   2      4\n",
       "2   3      3\n",
       "3   4      5\n",
       "4   5      7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('output_data/sample_submission.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = nn.forward(x_test.reshape(-1,784))\n",
    "df['class'] = list(np.argmax(softmax(output2),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('baseline.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15400"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
