{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed172964a7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN,Dense,Activation, Flatten,GRU,LSTM,TimeDistributed, Dense\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "seed_everything(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.load('mnist.train.npy')\n",
    "y_train = np.load('mnist.trainlabel.npy')\n",
    "x_test = np.load('mnist.test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Flatten(input_shape = x_train.shape[1:]))\n",
    "nn.add(Dense(256, activation=\"tanh\"))\n",
    "nn.add(Dense(10))\n",
    "nn.add(Activation('softmax'))\n",
    "nn.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "x,xt,y,yt = train_test_split(x_train,y_train,test_size = 0.2)\n",
    "\n",
    "y = np_utils.to_categorical(y, 10)\n",
    "yt = np_utils.to_categorical(yt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(x,y,epochs=20,validation_data=(xt,yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train on 44800 samples, validate on 11200 samples\n",
    "Epoch 1/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.2964 - acc: 0.9129 - val_loss: 0.1944 - val_acc: 0.9469\n",
    "Epoch 2/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.1423 - acc: 0.9578 - val_loss: 0.1358 - val_acc: 0.9583\n",
    "Epoch 3/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0916 - acc: 0.9726 - val_loss: 0.1214 - val_acc: 0.9614\n",
    "Epoch 4/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0648 - acc: 0.9805 - val_loss: 0.0988 - val_acc: 0.9700\n",
    "Epoch 5/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0470 - acc: 0.9858 - val_loss: 0.0876 - val_acc: 0.9727\n",
    "Epoch 6/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0334 - acc: 0.9904 - val_loss: 0.0877 - val_acc: 0.9749\n",
    "Epoch 7/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0244 - acc: 0.9935 - val_loss: 0.0824 - val_acc: 0.9742\n",
    "Epoch 8/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0165 - acc: 0.9958 - val_loss: 0.0885 - val_acc: 0.9749\n",
    "Epoch 9/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0139 - acc: 0.9964 - val_loss: 0.0882 - val_acc: 0.9751\n",
    "Epoch 10/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0109 - acc: 0.9972 - val_loss: 0.0891 - val_acc: 0.9745\n",
    "Epoch 11/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0071 - acc: 0.9986 - val_loss: 0.0896 - val_acc: 0.9739\n",
    "Epoch 12/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0058 - acc: 0.9990 - val_loss: 0.0866 - val_acc: 0.9767\n",
    "Epoch 13/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0996 - val_acc: 0.9733\n",
    "Epoch 14/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0917 - val_acc: 0.9764\n",
    "Epoch 15/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0843 - val_acc: 0.9789\n",
    "Epoch 16/20\n",
    "44800/44800 [==============================] - 6s - loss: 6.2328e-04 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9785\n",
    "Epoch 17/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0089 - acc: 0.9968 - val_loss: 0.0983 - val_acc: 0.9754\n",
    "Epoch 18/20\n",
    "44800/44800 [==============================] - 7s - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0910 - val_acc: 0.9779\n",
    "Epoch 19/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0868 - val_acc: 0.9793\n",
    "Epoch 20/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0884 - val_acc: 0.9791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.6537 - acc: 0.8333     \n",
    "Epoch 2/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.3735 - acc: 0.8952     \n",
    "Epoch 3/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.3302 - acc: 0.9060     \n",
    "Epoch 4/20\n",
    "44800/44800 [==============================] - 5s - loss: 0.3071 - acc: 0.9120     \n",
    "Epoch 5/20\n",
    "44800/44800 [==============================] - 5s - loss: 0.2903 - acc: 0.9165     \n",
    "Epoch 6/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.2770 - acc: 0.9207     \n",
    "Epoch 7/20\n",
    "44800/44800 [==============================] - 4s - loss: 0.2655 - acc: 0.9239     \n",
    "Epoch 8/20\n",
    "44800/44800 [==============================] - 5s - loss: 0.2546 - acc: 0.9271     \n",
    "Epoch 9/20\n",
    "44800/44800 [==============================] - 5s - loss: 0.2444 - acc: 0.9305     \n",
    "Epoch 10/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.2348 - acc: 0.9321     \n",
    "Epoch 11/20\n",
    "44800/44800 [==============================] - 5s - loss: 0.2254 - acc: 0.9356     \n",
    "Epoch 12/20\n",
    "44800/44800 [==============================] - 7s - loss: 0.2163 - acc: 0.9385     \n",
    "Epoch 13/20\n",
    "44800/44800 [==============================] - 7s - loss: 0.2076 - acc: 0.9410     \n",
    "Epoch 14/20\n",
    "44800/44800 [==============================] - 8s - loss: 0.1995 - acc: 0.9433     \n",
    "Epoch 15/20\n",
    "44800/44800 [==============================] - 8s - loss: 0.1917 - acc: 0.9455     \n",
    "Epoch 16/20\n",
    "44800/44800 [==============================] - 8s - loss: 0.1845 - acc: 0.9481     - ETA: 1s - \n",
    "Epoch 17/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.1774 - acc: 0.9502     \n",
    "Epoch 18/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.1711 - acc: 0.9519     \n",
    "Epoch 19/20\n",
    "44800/44800 [==============================] - 5s - loss: 0.1650 - acc: 0.9534     \n",
    "Epoch 20/20\n",
    "44800/44800 [==============================] - 6s - loss: 0.1594 - acc: 0.9557 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
